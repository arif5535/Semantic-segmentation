{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1YTRCzdpbR8Hg60ddWDnJi8FBJlXQuDp5",
      "authorship_tag": "ABX9TyOU0bpwC+Tuv+0CrP+Ig2eR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arif5535/Semantic-segmentation/blob/main/final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.9.1 google-auth-oauthlib pandas-gbq"
      ],
      "metadata": {
        "id": "2ipsQd0SFppv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "SDjjnfeOuaSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/qubvel/segmentation_models"
      ],
      "metadata": {
        "id": "uF6plKybuk3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import segmentation_models as sm"
      ],
      "metadata": {
        "id": "pAyJs7h9uqIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib"
      ],
      "metadata": {
        "id": "5hS0V9ZAuwuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "dQRkM30du4a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "77LPJLspvAHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BACKBONE = 'resnet34'\n",
        "preprocess_input = sm.get_preprocessing(BACKBONE)"
      ],
      "metadata": {
        "id": "yJGUWEg9vHXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Resizing images is optional, CNNs are ok with large images\n",
        "SIZE_X = 256 #Resize images (height  = X, width = Y)\n",
        "SIZE_Y = 256"
      ],
      "metadata": {
        "id": "ZeaAHVS5vJMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "-okN8u7mvY63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Capture training image info as a list\n",
        "train_images = []\n",
        "for directory_path in glob.glob(\"/content/gdrive/MyDrive/Segmentation/Images\"):\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
        "        #print(img_path)\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "        img = cv2.resize(img, (SIZE_Y, SIZE_X))\n",
        "        # img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        train_images.append(img)\n",
        "        # print(train_images)\n",
        "        #train_labels.append(label)\n",
        "#Convert list to array for machine learning processing\n",
        "train_images = np.array(train_images)"
      ],
      "metadata": {
        "id": "15orzkmvvTMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Capture mask/label info as a list\n",
        "train_masks = []\n",
        "for directory_path in glob.glob(\"/content/gdrive/MyDrive/Segmentation/Masks\"):\n",
        "    for mask_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
        "        mask = cv2.imread(mask_path, 0)\n",
        "        mask = cv2.resize(mask, (SIZE_Y, SIZE_X))\n",
        "        # mask = cv2.cvtColor(mask, cv2.COLOR_RGB2BGR)\n",
        "        train_masks.append(mask)\n",
        "        #train_labels.append(label)\n",
        "#Convert list to array for machine learning processing\n",
        "train_masks = np.array(train_masks)"
      ],
      "metadata": {
        "id": "2juAkFRJ-Psu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use customary x_train and y_train variables\n",
        "X = train_images\n",
        "Y = train_masks\n",
        "\n",
        "Y = np.expand_dims(Y, axis=3) #May not be necessary.. leftover from previous code"
      ],
      "metadata": {
        "id": "TwX7BYaa-t0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "SE4P8Pgs-yC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess input\n",
        "x_train = preprocess_input(x_train)\n",
        "x_val = preprocess_input(x_val)"
      ],
      "metadata": {
        "id": "xWP4DSSg-2PL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "from tensorflow.keras.utils import get_file"
      ],
      "metadata": {
        "id": "CgEOM3vU_Dpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = sm.Unet(BACKBONE, encoder_weights='imagenet')\n",
        "model.compile(optimizer='Adam', loss=sm.losses.bce_jaccard_loss, metrics=[sm.metrics.iou_score])\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "shGpqNvuNYNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#type_cast_float_32\n",
        "\n",
        "y_train = tf.cast(y_train, tf.float32)\n",
        "y_val = tf.cast(y_val, tf.float32)"
      ],
      "metadata": {
        "id": "YQsWeTfqscvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train model\n",
        "\n",
        "history=model.fit(x = x_train,\n",
        "          y = y_train,\n",
        "          batch_size=32,\n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "id": "N_ktEho8V75I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = model.evaluate(x_val, y_val)\n",
        "#plot the training and validation accuracy and loss at each epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OfGDA_pW0an2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/gdrive/MyDrive/Segmentation/model.h5')"
      ],
      "metadata": {
        "id": "DRji47Cx1XtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.load_model('/content/gdrive/MyDrive/Segmentation/model.h5', compile=False)"
      ],
      "metadata": {
        "id": "kCWuh6ZN2EU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test on a different image\n",
        "#READ EXTERNAL IMAGE...\n",
        "test_img = cv2.imread('/content/gdrive/MyDrive/Segmentation/Images/401.jpg', cv2.IMREAD_COLOR)\n",
        "test_img = cv2.resize(test_img, (SIZE_Y, SIZE_X))\n",
        "test_img = cv2.cvtColor(test_img, cv2.COLOR_RGB2BGR)\n",
        "test_img = np.expand_dims(test_img, axis=0)\n",
        "#plt.imshow(test_img,cmap = 'gray')\n",
        "prediction = model.predict(test_img)"
      ],
      "metadata": {
        "id": "L5ON-YJX2Qu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#View and Save segmented image\n",
        "prediction_image = prediction.reshape(mask.shape)\n",
        "plt.imshow(prediction_image, cmap='gray')\n",
        "plt.imsave('/content/gdrive/MyDrive/Segmentation/test0_segmented.jpg', prediction_image, cmap='gray')"
      ],
      "metadata": {
        "id": "HAbLeKdS3Fjp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}